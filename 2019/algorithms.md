# Algorithms: Not That Important
Recently, I had a pretty challenging problem to solve for my job. I have been programming for over a decade, and these sorts of problems only seem to come up once a year or so. It's somewhat reassuring that I can still solve the sorts of problems I faced when I was back in college. The big difference is that in college someone had already found a solution and the professor kindly explains the mechanics of that solution. Any talented developer, within a year of learning basic programming, should be able to translate a spoken explanation into functional code. In the real world, you can't be sure a solution even exists.

The amazing part about development is that you can even start tackling a problem at all, of any complexity. I frequently think about how I approach problems because it's still a bit of a mystery to me. I have been posed with some serious challenges in my career and have had a 100% success rate on all of them. To be fair, there have been times where I wasted a lot of time trying to solve problems using a completely wrong approach and suddenly take a sharp right turn to finally get where I needed to go. But that time wasn't really wasted because it helped me to further understand the problem and seek out whatever new information I needed to find a better solution, find the right questions to ask, separate out one problem into smaller independent problems, and hunt down solutions to similar problems.

One of the fundamental skills I use all the time is modeling. People talk a lot about modeling, whether it be for database design or object-oriented programming, what have you. Reading literally dozens on books on those topics, one thing is crystal clear: most people are awful at this... especially the people who think they are good at it.

While working on my most recent challenge, you would have seen me drawing pictures of boxes, numbered 1-N, on my notebook on my desk. Maybe 10% of the picture was actually on paper, but in my mind those images were alive, playing out faster than I could ever hope to scribble them down. As I drew them out, thinking about different scenarios, scratching out boxes, drawing arrows from here to there, I was constantly refining my understanding and asking the next question. Before too long, I felt drawing, writing down my thoughts, and spitting out pseudo code was becoming pointless and just start coding. Then I went back and forth until I ran out of things to try.

## A not-so-new algorithm
If you check out some of my open source projects, you'll see I spent a lot of time early in my career working on an algorithms library that eventually came to be named [NDex](https://github.com/jehugaleahsa/ndex). It's enormous. It became mostly obsolete when .NET introduced LINQ, which is funny (*maybe not so funny!*) because that's about the time it went v1.0.

I actually spent an enormous amount of time researching algorithms in various projects, from the C++ STL to [Power Collections](https://www.wintellect.com/power-collections-library/). How do I make this feel like C#? How do I give them a more developer-friendly interface? How can I avoid the overhead of calling a virtual function 10,000 times inside of this tight loop? Most importantly, what unit tests can I write to fully exercise this code and what are some bizarre edge cases? By the end of that project, I was intimately familiar with most of the algorithms in the C++ STL and why there are actually a lot of edge cases that fall in with other, more common, cases because the algorithms are elegantly designed.

Being so familiar with the plethora of algorithms out there, after implementing my new algorithm for work the other day, I realized it was just another, somewhat-common algorithm, with a small tweak or two. Okay, so it's not-so-new then. Actually, recognizing the algorithm helped me to think about the problem in a whole new light. Somehow I had reinvented that algorithm and had not even gotten to the point where I recognized I was solving a specific subset of a more general problem. That's unusual, but pretty cool.

There are some genuinely unique solutions to problems out there. Just watching a video showing how different sorting algorithms work, you can appreciate how magical some solutions seem to be: https://www.youtube.com/watch?v=kPRA0W1kECg. I used to enjoy watching Windows de-frag a hard-drive because it would magically make holes and then fill them back in and at the end of the process all your file chunks were next to each other. I think about just how magical the algorithm must be today that can do that sort de-fragmentation on-the-fly while the file system is in use. It made de-fragmentation obsolete.

That all said, you might find it surprising to hear me say that algorithms aren't really that important. There are some successful companies out there, such as HackerRank, that make a business out of convincing developers that solving their problems will make them better developers and give them an edge in the IT marketplace. You can post your ranks on social media and even take their tests during interviews. Here's the thing though: unskilled developers just disregard these sites saying things like, "Every problem just involves knowing some trick or other", and that's not far from the truth, and talented developers eventually just get bored of it. They remind me of programming assignments in college, where the solution is already known and you're just reinventing the wheel, except you make the wheel square the first time round.

The truth is you just don't need to write innovative algorithms on a daily basis. To be frank, it's odd that I've needed to do it as often as I have in my career. It might be that I'm just too willing and eager to face those problems. The plain truth is that most of the time, our code is comprised of very basic if-statements and for-loops. That's a good thing because most of the hard problems should already be solved for us and we just need to crank out the remaining, monotonous wiring up. We should just be dealing with poorly design interfaces and outdated technology.

When I look at why things do end up being complicated, more often than not, it's because of bad design choices. Most of those bad design choices come down to bad modeling. My needing to write complex algorithms so often in my past was probably because, back then, I wasn't as good at modeling as I am today. An equally likely source of complexity was that the technology just wasn't there 5-10 years ago; for example, you used to have to implement grouping and other data manipulation operations using lookup tables where, today, most environments have grouping operations and/or functional programming concepts in place that simplify the whole process. I think it was mostly a "me problem", though.

## No more wizards and sages
I've been doing this long enough now that I've seen a lot of big names fade in and out of existing in the software industry. We used to have the "Uncle Bob"s who people followed and practically worshipped. There's still a lot of hero worship going on in the IT industry but I feel like it's changed a lot in recent years. I feel guys like [Dan Abramov](https://twitter.com/dan_abramov) are getting more attention now because they are focused on actual solutions and less on general-purpose observations about the software industry. People want to know better ways to organize their data in react apps (you know, practical stuff), and less on "you need to do more up-front design and use agile" speeches.

The reality of the situation is our industry is plagued by an ever-increasing influx of beginners who quickly peter out (or enter management) and an ever-smaller number of developers with hard-earned experience getting five or more years under their belt.

Too many projects get off on the wrong foot because the intern is writing the next phase of the company's core product. Too many inexperienced developers become management and think that gives them insight into what development is like. Too often, the experienced developer who wants to keep things bare metal alienates juniors who haven't had enough time to learn all the foundational skills. There's always more to learn about CSS, function programming, concurrency, cloud services, authentication, DevOps, etc. No one useful can be a specialist anymore.

## What do we need?
It's hard to define what makes a good developer anymore. Interviews are harder than ever before. Most of us in the industry aren't even sure what we're looking for in a job or in a company anymore. For me personally, I want to know there are challenges I can help solve, making a difference. But, more importantly than that, I just want people I can eat lunch with everyday and joke around with. A lot of younger, ambitious developers don't get that -- I know I didn't.

A lot of companies don't know how to keep their developers free. They just keep dumping more on them until they are almost uninvolved in development at all, or they transition all of their talent into managerial roles, or overload them until they quit.

The few of us with talent that can stick it out beyond 5 years are really far and few between. I personally have shied away from several opportunities for "advancement" and I wonder about the guys who actively seek it out. Most of my experience in that realm has been the recognition that money is *real* and people are emotional, crybaby bed-wetters (and this is why I shouldn't manage people). I want to be the 90 year-old engineering nerd working in his corner. That makes me rare. I used to worry that staying at the bottom would make me more expendable or ultimately less employable but I see companies fire middle management more than anyone and talented developers last of all. I also found I make a much better tech lead staying close to the battle front; I am a general that leads from the front-lines; I'm down in the trenches.

At my current job I am working as a "software engineer". Previously I was an "architect". Once I realized I didn't care about the "architect" title, finding a better-paying job was easy. In fact, while looking for an "architect" position, all I found were jobs where I wasn't writing code, just telling other people to write code. Blah! Yuck!

What we really need is less focus on frameworks and more on fundamentals. This is harder than it sounds. Imagine you are new to development. The heart of software development is still a bit of a mystery to you but, like everybody else, you got into it because you were interested in making a web page for your wedding, or creating a WoW mod or thought you could write an app to predict the stock market trends, or you wanted to make video games. Guess what? Everyone starts the same way. No one sits around and thinks to themselves, "Boy oh boy, I can't wait to write that business app that lets users start entering their data into a form instead of an Excel spreadsheet." I mean, that's what we do, really.

It's asking too much to have entry-level guys read book after book about HTML, JavaScript, CSS, relational databases, concurrency, algorithms, language de-jour, functional programming, OOP, XML/JSON, source control, automating deployments, etc. and not give them a reason to use or retain any of it. You learn in this industry by **doing** and looking up how.

Unfortunately, it's not until you've finally gotten around to reading or talking to the right people that you start to see why those solutions make sense or how to avoid those situations entirely. Honestly, once you know the fundamentals of web development, things like REST make all the sense in the world and you really wonder why there's all these frameworks in place for something that should be so straight-forward and simple. You forget that, when you started, things like GET vs POST, multi-part form-data, etc. were still incredibly fuzzy -- not the clear picture of a bunch of plain-text messages with headers being send back and forth you have today.

But we need more focus on the fundamentals. We need frameworks that expose the low-level while still keeping things simple. ASP.NET WebForms ultimately failed because there were too many abstractions between the tooling and the HTML that ended up in the browser. We need short examples that show how to achieve the 90%, with thorough API docs for the guy willing to do the research. But, most of all, we need to stop hiding things, exposing the new guy early on. We need to say, "Start out learning som basic PHP and, when you're ready, let's look into MVC frameworks and SPAs." Point out what types of languages, libraries and tools people in different industries are using. Allow people to make their own learning paths. Today, I feel like this is a bit of a shot in the dark for most people.

I have this sinking feeling whenever I start looking into data science and machine learning. It is overwhelming and it's not clear what direction I want to take. In my early days of programming, when all I knew was some basic C++, I wasn't thinking about large-scale applications. I was super happy just printing out to the console; I just didn't care. Maybe I was too young and naive to be worried about how to convert those skills into a paying job at the time. Perhaps, had someone given me a better feel for the scale of software development in the real world, I might have shied away from it before I had a chance to get this far. It makes me wonder if going into IT solely in hopes of getting a job is the wrong attitude and approach altogether. Maybe you just need to enjoy coding first and then the career comes second. Perhaps that's the secret sauce to any practice, though.