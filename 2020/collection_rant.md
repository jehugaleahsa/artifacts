# A Rant About Collections

**tl;dr** `equals`/`hashCode` should be separate concerns *and* ordered hash tables/sets should be a part of *every* language's standard library!

## Minimal Standard Library
With development tools making it easier to use third-party software, such as `npm`, `NuGet`, `cargo`, etc., there seems to less of an onus on languages providing *huuuge* standard libraries (or frameworks) anymore. I could go on a whole other rant about languages *not* providing adequate standard functionality, but instead I will focus on what should be the absolute bare minimum.

Imagine you just started programming last week, in whatever language. You haven't really had the opportunity to learn what other programs look like in that language yet, let alone start to write idiomatic code. You just need to accept that you're going to format the code poorly, you're not going to use the "right" feature here or find the most elegant solution there. The good thing is, after you've programmed long enough, you can usually fake your way to a working solution in any language via brute force if you really have to.

I would argue across languages that there's an expectation from developers of a bare-minimum set of faculties, whether they are built into the language or are part of a standard library. I think minimally, those features/libraries include: strings (text processing), collections and I/O. That's a small list and it's fair to argue that strings are just a specialized type of collection, so it is even smaller. 

Comically, I can honestly say that in most of the applications I've worked on, I/O was rarely in the form of reading/writing to the console or touching files. However, I/O in a particular language usually says a lot about it. Is it just a thin abstraction over reading bytes from a hard-disk? Is is some intricate abstraction involving streams of streams? How is the file closed when you're done using it? How are errors handled? These decisions end up giving a language its *flavor*.

So, obviously, collections are really important to a language. You might argue that collections could "easily" be implemented as separate third-party packages, as well. For the most part I agree; however, minimally, the concept of arrays must be fundamental to a language. You might argue, looking at C, that arrays are *just pointers*; however, this isn't necessarily true. In C, when you allocate an array on the heap, the heap keeps track of the array's length. Otherwise, the length of arrays allocated on the stack is tracked by the compiler in order to push and pop memory off the stack. So, at a minimum, all languages need arrays.

But... just like I/O, how a language lets you interact with collections ultimately sets the mood for development in that language. Imagine if a language pushed off the responsibility of collection implementation to third-party libraries. There'd be a total lack of consistency! Not just in how developers interact with the collections, but in terms of setting expectations about performance, reliability, security (think about recent exploits involving hash tables!) and so on.

Furthermore, I would argue that there's a cost associated with third-party libraries. Developers and companies are much less hesitant to use standard functionality. Why? Because everyone knows these libraries. They're "standard", right? Otherwise, every developer you hired would have their own opinions about which library is better. Just look how much division exists in the Java community because of Guava!

So, collections should be part of a standard library. They should strive to provide the best performance and usability for general-purpose development. If developers need specialized collections for their particular problem domain, then, and only then, does grabbing a third-party collection really make sense.

## What should be standard then?
There are a ton of collections out there. Minimally, languages should have arrays. Okay, we've established that. If we're talking about C, then we're already done! However, most languages will also want dynamically growing array-like classes (aka., `vector` or `ArrayList` or whatever it's called). Most languages will also want to have hash-table collections such as maps (associative arrays or dictionaries) and sets.

Most languages also seem to provide a double-ended queue (deque) for fast insertion and removal from both the front and end of the collection. They also typically provide some binary red-black tree for maps and sets, as well. "Adapter" collections like queues, stacks, etc. are usually implemented *in terms of* one of the other collection types. You might even get an array-backed heap for implementing priority queues.

Bare minimum, a language should probably have an array list and a map. These two collection types are *just different enough* from each other that finding a universal set of abstractions over them will give your language it's own flavor.

## Ordered collections
Most developers don't understand the difference between "sorted" and "ordered". Things like SQL's ORDER BY clause just add to this confusion. Ordered just means items can be retrieved in a predicable way. Sorted is really just a special case, where values are *sorted*, therefore making the order predictable. For instance, strings are often sorted lexicographically, or numbers are sorted numerically, or dates are stored chronologically. But there are other ways to order items in a collection that don't involve sorting.

> Someone particularly anal about their definitions might argue that the order that "equal" items are returned from a sorted collection isn't guaranteed/predictable unless the sorting algorithm or underlying data structure is "stable". Fine, whatever! I just didn't want to confuse people!

Normally, when a language or library indicates that a collection is ordered, it is referring to "insertion order". In other words, values will be retrieved in the same order that they were added to the collection.

Sequential lists, such as arrays, array lists, FIFO queues, and deques, are ordered by their very nature. Binary trees are typically used to create "sorted" collections, so items are retrieved in sorted order, rather than the order they were inserted. Maps and sets, usually, will return their items in a seemingly random order (the order is actually predictable if you understand how hash tables work under the hood).

However, using more memory (and at the risk of introducing CPU cache misses), maps and sets can be implemented so that their entries can be returned in insertion order. Most ordered maps and sets are implemented using a linked list. Each key/value pair in the hash table is wrapped in a linked list node, pointing to its predecessor and successor. Using a linked list makes it efficient to insert new map entries, since only two pointers/references need updated. And deletions are fast too, since the predecessor just needs updated to point to the successor and vice versa.

The major criticism of ordered maps/sets is the same criticism made for linked lists: they lead to CPU cache misses. Modern computer hardware can achieve amazing performance improvements whenever data is found sequentially in memory. Following pointers around can prevent these types of optimizations. However, most hash tables are implemented internally using linked lists already. Each "bucket" is a list of values sharing the same hash code. These are typically linked lists because then re-hashing these values when the hash table grows is cheaper and memory usage is more predictable. In an ideal hash table, each linked list has exactly one element and many hash tables have optimizations in place to take advantage of this fact. Furthermore, hash tables usually employ tricks to keep the linked list nodes close to each other in memory (aka., locality of reference). For ordered maps/sets, tossing another linked list into the mix isn't as big of a deal as people think. The most costly thing is adding the memory for two extra pointers (64-128 bits on modern architectures). If you're concerned about 128 bits, you're not the audience I'm trying to talk to. 😅

Ordered maps and sets are more common at my current job than at any of my previous jobs. On many of my open source projects, I have needed classes to hold things like function parameter lists and schema information (database columns) where order is very important but I also need to look things up by their name. My current company reads a lot of files only to modify them and spit them back out — keeping them in roughly the same order is paramount to minimizing diff sizes.

At this point in my career, I feel like if a language provides much more than an array list and a map, they should include an ordered map in their arsenal. Java has `LinkedHashMap`. Python had `OrderedDict` but now the built-in dicts are ordered (as of CPython 3.5). JavaScript's `Map` is ordered. .NET has a non-generic `OrderedDictionary`. 

I feel like languages should adopt ordered hash tables if they haven't already. C++ has to deal with a lot of politics around finding a general-purpose implementation that everyone can agree on adding to the STL, but I would argue it is worth it. Rust needs to adopt one, as well. .NET needs to officially introduce a generic `OrderedDictionary` (I know there's a petition, at least).

I would argue that, today, more often a binary tree is more specialized than an ordered hash table, being less likely to actually provide any performance benefit in everyday computing, whereas being able to keep items in insertion order while providing constant-time lookup is a *fairly* common need. Relying on third-party implementations is *not* desirable.

## Equals/HashCode as a separate concern
While we're on the subject of hash tables... It annoys me that in C# and Java that `equals` and `hashCode` are part of the `Object` class. I appreciate having a common ancestor for all types; however, equality is a deceptively advanced topic that seems to get belabored in every book introducing hash table-based collections.

Things like immutability and mathematical terms like the reflexive property and "[transitivity](https://en.wikipedia.org/wiki/Equality_(mathematics)#Basic_properties)" get thrown into the mix. Entire chapters are dedicated to the history of `equals` and `hashCode` in Java and how everyone gets them wrong. There are so many pitfalls, Hibernate's documentation recommends only creating hash codes based on [natural keys](https://docs.jboss.org/hibernate/orm/5.0/mappingGuide/en-US/html/ch07.html) or using the built-in [identity-based implementation](https://docs.oracle.com/javase/7/docs/api/java/lang/System.html#identityHashCode(java.lang.Object)).

Most of the time, `equals` and `hashCode` should be based off of one or more uniquely identifying fields in an object, like a database ID or an email address. In many languages, rather than implement `equals` and `hashCode` yourself, you provide a lambda returning the key value or a tuple of key values. Often your keys will be primitive types, like numbers or strings, where the language already provides an optimal implementation of `hashCode` and an optimal implementation for combining hash codes from multiple values. This eliminates 99% of the reasons why you'd want to write your own hashing function.

An even better reason not to place `equals` and `hashCode` on `Object` is that depending on where you are in your code, you might want to key the same object differently. You might want to build a lookup to users based on database ID in one spot, their LDAP OID somewhere else, their emails elsewhere and so on. This is especially common when trying to match up records coming from different systems (aka, software integration) or when trying to find a unique list of records.

Worse, imagine in your database-heavy application you are following Hibernate's recommendation to use the default identity-based `hashCode` and `equals` implementations. Then, a poor developer unwittingly implements them based on the database ID. It seems innocent enough and it definitely lets his code function as expected; however, he breaks the system in subtle and almost untraceable ways. This isn't a problem specific to Hibernate either - the same problems exist in Entity Framework and other ORMs, especially regarding the insertion of new records or marking entities detached and then re-attaching them later.

I will be the first to admit that there is *almost always* a work-around to this problem, as any seasoned Java developer will tell you. You can always wrap one class in another with a different `hashCode`/`equals` implementation or just use a primitive as your `Map` key. However, things are much harder in JavaScript where you cannot *really* override `equals`/`hashCode` at all! In JavaScript, you end up doing hacks like creating string representations of your keys. There's a [proposal](https://github.com/tc39/proposal-record-tuple) to add record types to JavaScript, which will hopefully remedy this. To be honest, this problem is rare enough that most people don't know there's anything to complain about.

In .NET, hash table-based collections accept [IEqualityComparer](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.dictionary-2.-ctor?view=net-5.0#System_Collections_Generic_Dictionary_2__ctor_System_Collections_Generic_IEqualityComparer__0__) objects, that allow overriding the hashing and equality comparisons. In C++, the hashing and comparison operations are part of the [collection's type](http://www.cplusplus.com/reference/unordered_map/unordered_map/)!

Honestly, libraries without this facility just feel like toy libraries to me now. I was disappointed to see Rust didn't get this right. 😞 Languages where `Object` provides `hashCode`/`equals` just feels like a bad fad. This is a total violation of separation of concerns. Somehow, every object in these languages is concerned with how they are stored in a hash table. What?!?! Fortunately, Rust did get this one right. 👍

## Conclusion
One thing that dawns on you after you've been programming for a long time is that there's always a list of things that annoy you about a language. The more achievable they seem, the more they seem to irritate you. I feel like the ordered hash table thing is just a lack of industry knowledge concerning the topic. The `equals`/`hashCode` thing is in the same camp.

It especially sucks when one language does something revolutionary (based on good design principles and real-world analysis) and then another new language comes along and takes the same wrong turn as previous languages. Part of that, is that there's just not enough developers learning more than one or two languages (polyglot). Fortunately, language designers *do* tend to [share](https://www.sigplan.org/Conferences/) their knowledge and experience so things like lambdas and inferred typing have been widely adopted in recent years.

Overall, relying on third-party implementations to supplement (or even augment) your language is doomed to fail in some way or another. Equally bad, trying to compensate for lacking language features through third-party libraries and hacks makes the language harder to learn and maintain (I'm looking at you C++!!!).

Consider Fortran... early versions of that language didn't even support [structured programming](https://en.wikipedia.org/wiki/Structured_programming) using if/else statements and loops. Many MACRO based tools came out later to supplement the language but gradually the language failed to adapt... and then it was [too late](https://en.wikipedia.org/wiki/Fortran#FORTRAN_77).

I feel like the phrase "general-purpose programming language" is a misnomer. I feel like there is becoming a discerning breakdown into the following camps: 
* low-level languages like C, C++ and Rust, where high-performance and predictable run-times are needed, like for embedded devices, drivers, real-time systems, stock trading, and gaming.
* business languages like C# and Java, where productivity and portability, along with a massive framework at your disposal justify any loss in performance.
* scripting languages like JavaScript and Python where performance is achieved via scalable infrastructure and the lack of type safety is compensated for using pre-compilers or increased unit testing. Or code that is short-lived or constantly evolving, like shell scripts, ML experiments, etc.

I think JavaScript has begun to spread into the industry camp thanks to Node.js/npm, TypeScript, WASM, and the latest language features. C#'s recent introduction of `Span<T>`, dramatic performance improvements, and increased portability has allowed it to start entering the low-level category. I am hopeful Rust can prove itself as a low-level language and yet find itself a viable industry language. My feeling is an expressive-enough low-level language, like Rust, could even be found intruding into the scripting arena.